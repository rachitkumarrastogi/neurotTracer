# ğŸ“˜ **README.md â€” TraceNeuro / Cognitive Authenticity Engine (Working Name)**

*(Working namespace: traceneuro/core â€” final brand TBD)*

---

## ğŸ“š **Complete Platform Documentation**

**ğŸ‘‰ For a comprehensive, detailed summary of the entire platform (features, tech stack, WIP, open questions, architecture, API, database, everything), see:**

**[`docs/PLATFORM_SUMMARY.md`](docs/PLATFORM_SUMMARY.md)** - Complete technical summary with all minute details

---

# ğŸ§  **TraceNeuro â€” Cognitive Authenticity Engine (Human Cognition Fingerprint + Hybrid Detection)**

TraceNeuro is an **LLM-proof Cognitive Authenticity Engine** that identifies human cognitive signatures inside text using *reasoning patterns*, *semantic drift*, *cadence irregularity*, *stylometry*, and *non-linear thought markers*.

Unlike "AI detectors" (perplexity, logits, stylistic heuristics), TraceNeuro analyzes **how the mind thinks**, not **how the model writes**.

This makes it resilient against:

* paraphrasing
* rewriting
* GPT/Claude "humanization" modes
* future LLM improvements
* hybrid AI+human text

TraceNeuro's output is a multi-component **HumanScoreâ„¢**, built from real cognitive markers that AI still fails to simulate consistently.

---

## ğŸš€ **Why TraceNeuro Exists**

Traditional AI detectors are built on:

* token probabilities
* burstiness/perplexity
* surface-level linguistic cues

These fail instantly against:

* simple paraphrasing
* hybrid editing
* GPT-5+ depth
* humanization tools
* prompt engineering

**TraceNeuro is not a detector.**

It's a **cognitive authenticity layer**.

It asks:

> "Does this text contain the underlying cognitive patterns associated with human reasoning?"

This is the future of:

* compliance
* publishing
* academic integrity
* journalism
* enterprise governance
* AI/hybrid authorship verification

---

# ğŸ—ï¸ **System Architecture (MVP Architecture Diagram)**

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚       Web / CLI Client       â”‚
                          â”‚ (upload, paste, API request) â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”
                               â”‚  Edge Gateway/API   â”‚
                               â”‚  Auth, rate limits  â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â–¼                        â–¼                        â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Preprocessing Svc â”‚    â”‚  Cognitive Marker     â”‚   â”‚  LLM Baseline Svc  â”‚
       â”‚ - cleaning        â”‚    â”‚    Extractor          â”‚   â”‚  (optional)        â”‚
       â”‚ - segmentation    â”‚    â”‚ - drift vectors       â”‚   â”‚ - perplexity check â”‚
       â”‚ - tokenization    â”‚    â”‚ - cadence variance    â”‚   â”‚ - baseline compare â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ - hedging signals     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚              â”‚ - metaphor rarity      â”‚             â”‚
                 â–¼              â”‚ - coherence breaks     â”‚             â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ - stylometric graph    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Feature Encoder   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ Fusion Layer        â”‚
       â”‚ - numerical vecs  â”‚               â”‚                 â”‚ - marker weighting  â”‚
       â”‚ - embeddings      â”‚               â–¼                 â”‚ - final scoring     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚              â”‚  HumanScore Engine    â”‚               â”‚
                 â–¼              â”‚ - human index         â”‚               â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ - AI index            â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Report Builder    â”‚    â”‚ - hybrid index        â”‚   â”‚ Results API / Dashboard UI â”‚
       â”‚ - heatmaps        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ - breakdown       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“¦ **Repository Structure**

```
neurotrace/
  â”œâ”€â”€ engine/
  â”‚     â”œâ”€â”€ preprocessing/
  â”‚     â”œâ”€â”€ markers/
  â”‚     â”‚     â”œâ”€â”€ drift/
  â”‚     â”‚     â”œâ”€â”€ cadence/
  â”‚     â”‚     â”œâ”€â”€ hedging/
  â”‚     â”‚     â”œâ”€â”€ metaphor/
  â”‚     â”‚     â”œâ”€â”€ coherence/
  â”‚     â”‚     â””â”€â”€ stylometry/
  â”‚     â”œâ”€â”€ embeddings/
  â”‚     â”œâ”€â”€ fusion/
  â”‚     â””â”€â”€ humanscore/
  â”‚
  â”œâ”€â”€ api/
  â”‚     â”œâ”€â”€ routes/
  â”‚     â”œâ”€â”€ scoring/
  â”‚     â”œâ”€â”€ auth/
  â”‚     â””â”€â”€ report/
  â”‚
  â”œâ”€â”€ web/
  â”‚     â”œâ”€â”€ dashboard/
  â”‚     â”œâ”€â”€ components/
  â”‚     â””â”€â”€ auth/
  â”‚
  â”œâ”€â”€ data/
  â”‚     â”œâ”€â”€ human/
  â”‚     â”œâ”€â”€ ai/
  â”‚     â””â”€â”€ hybrid/
  â”‚
  â”œâ”€â”€ docs/
  â””â”€â”€ tests/
```

---

# ğŸ“… **Roadmap (Realistic, Non-Bullshit)**

## **Phase 0 â€” Foundations (Week 1â€“2)**

* Setup repository + monorepo tooling
* Implement preprocessing engine
* Implement basic API
* Collect 500 human samples (pre-2012 blogs, Reddit 2009â€“2012, diary corpora)

## **Phase 1 â€” Cognitive Marker MVP (Week 3â€“6)**

* Build semantic drift extractor
* Build cadence variance module
* Build hedging detector
* Build metaphor rarity counter
* Build coherence break detector
* Build stylometric fingerprint graphs

## **Phase 2 â€” Fusion Layer + HumanScore (Week 6â€“8)**

* Weight markers
* Normalize marker distributions
* Hybrid score integration
* HumanScoreâ„¢ v1

## **Phase 3 â€” UI + API Launch (Week 8â€“10)**

* Minimal dashboard
* Upload or paste-box
* JSON API endpoints
* Save scoring history
* Export reports

## **Phase 4 â€” Hybrid Detection Engine (Week 10â€“12)**

* Build training set (Humanâ†’AIâ†’Human)
* Classify hybrid segments
* Add hybrid index to HumanScoreâ„¢

## **Phase 5 â€” V1 (3â€“6 months)**

* Scaling
* Caching
* Deep reporting
* Team mode
* Audit logs
* Enterprise API
* Model fine-tuning on custom corpora

---

# ğŸ§© **Core Algorithms (High-level)**

TraceNeuro uses a multi-signal approach:

### âœ” Drift Vector Analysis

Tracks meaning changes across sentences.

### âœ” Cadence Variability

Humans produce uneven pacing; AI is too smooth.

### âœ” Hedging & Cognitive Bias Markers

Humans hedge inconsistently; AI hedges predictably.

### âœ” Metaphor Rarity & Asymmetry

Humans produce unique metaphors; AI reuses patterns.

### âœ” Coherence Breaks

Humans change direction mid-thought; AI rarely does.

### âœ” Stylometric Fingerprint

Individual cognitive "voiceprint" extracted as a graph.

Weighted and fused â†’ HumanScoreâ„¢.

---

# ğŸ”¨ **Initial Commit Layout (copy-paste this into your GitHub project board)**

### **Commit 1:** initialize monorepo, license, readme

### **Commit 2:** add preprocessing pipeline

### **Commit 3:** implement text cleaning & segmentation

### **Commit 4:** add drift module (baseline)

### **Commit 5:** add cadence analysis module

### **Commit 6:** add hedging detector

### **Commit 7:** metaphor rarity counter

### **Commit 8:** coherence break graph

### **Commit 9:** stylometric extractor

### **Commit 10:** embeddings + feature encoder

### **Commit 11:** fusion model (HumanScore)

### **Commit 12:** first API endpoints

### **Commit 13:** web UI scaffolding (Next.js)

### **Commit 14:** scoring history database

### **Commit 15:** deploy to Vercel (internal)

---

# ğŸ¤ **Contribution**

This project is in early prototyping stage.

Collaborators should follow:

* clean commits
* modular PRs
* architecture first, implementation second
* no features without test coverage
* use examples from `/data/`

---

# ğŸ“ **License**

MIT (may be upgraded to PolyForm or Custom Enterprise License later).

---

# ğŸš€ **Quick Start**

```bash
# Run setup script
./setup.sh

# Start the API server
cd api && uvicorn main:app --reload

# Start the web dashboard
cd web && npm run dev
```

---

# ğŸ“Š **Sample API Usage**

```bash
curl -X POST http://localhost:8000/api/v1/score \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Your text here...",
    "options": {
      "include_breakdown": true,
      "include_heatmap": false
    }
  }'
```

See `docs/sample_payloads.md` for more examples.

